{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Song lyrics for Robyn from azlyrics.com\n",
    "https://www.azlyrics.com/r/robyn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.lyrics.com/artist.php?name=Robyn&aid=214508&o=1\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# parse html\n",
    "page = str(BeautifulSoup(response.content))\n",
    "soup = BeautifulSoup(page, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### find_all with BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = []\n",
    "tables = soup.find_all(class_='tdata')\n",
    "for t in tables:\n",
    "    cells = t.find_all('td', class_=\"tal qx\")\n",
    "    for c in cells:\n",
    "        links = c.find_all('a')\n",
    "        for l in links:\n",
    "            #print(l.text)\n",
    "            #print(l['href'])\n",
    "            lyrics.append((l['href']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert into dataframe\n",
    "df_lyrics = pd.DataFrame(lyrics)\n",
    "#keep only lyrics links\n",
    "df_lyrics = df_lyrics[df_lyrics[0].str.contains('lyric')]\n",
    "#create full url\n",
    "df_lyrics['url'] ='https://www.lyrics.com'+df_lyrics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    https://www.lyrics.com/lyric/6774767/Robyn/Ain...\n",
       "2    https://www.lyrics.com/lyric/14076015/Robyn/An...\n",
       "4    https://www.lyrics.com/lyric/11948027/Robyn/An...\n",
       "6    https://www.lyrics.com/lyric/10529309/Robyn/An...\n",
       "8    https://www.lyrics.com/lyric/35561128/Robyn/Ba...\n",
       "Name: url, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lyrics['url'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### findall with re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re.findall('<a href=\\\"/lyric/+[a-z]+.\\\">$', str(soup), re.IGNORECASE)\n",
    "links_m2 = re.findall('href=..lyric.\\d+.Robyn.[^\\\"]+', str(soup), re.IGNORECASE)\n",
    "#links_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert into dataframe\n",
    "df_lyrics2 = pd.DataFrame(links_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create full url\n",
    "df_lyrics2['url'] ='https://www.lyrics.com'+df_lyrics2[0].astype(str).str[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics2['url'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pull lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing with just 3 urls\n",
    "# df_url = df_lyrics['url'].head(3)\n",
    "\n",
    "df_url = df_lyrics['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse all lyrics  and save as html files\n",
    "\"\"\"for l in df_url:\n",
    "    time.sleep(20)\n",
    "    url = df_url\n",
    "    response = requests.get(l)\n",
    "    page = BeautifulSoup(response.content)\n",
    "    filename = l.rsplit('/', 1)[-1]\n",
    "    filename = re.sub('[^a-zA-Z0-9-_*.]', '', filename)\n",
    "    page = page.prettify(\"utf-8\")\n",
    "    with open(f'lyrics_{filename}.html', \"wb\") as file:\n",
    "        file.write(page)   \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and clean pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(open(\"lyrics_Ain27tNoThing.html\"), \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(soup):\n",
    "    # filter only for body with lyrics\n",
    "    lyric = soup.find(class_='lyric-body').get_text()\n",
    "    #replace line breaks\n",
    "    lyric = lyric.replace('\\n',' ')\n",
    "    # remove words shorter than 3 characters\n",
    "    shortword = re.compile(r'\\W*\\b\\w{1,2}\\b')\n",
    "    lyric = shortword.sub('', lyric)\n",
    "    # convert into lower caps\n",
    "    lyric = lyric.lower()\n",
    "    # exclude numbers\n",
    "    lyric = ''.join(i for i in lyric if not i.isdigit())\n",
    "    # special characters\n",
    "    chars = re.escape(string.punctuation)\n",
    "    lyric = re.sub(r'['+chars+']', '',lyric)\n",
    "    return lyric\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Merging lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading all lyrics html from local directory and applying the cleaning \n",
    "all_lyrics = \"\"\n",
    "for l in df_url:\n",
    "    filename = l.rsplit('/', 1)[-1]\n",
    "    filename = re.sub('[^a-zA-Z0-9-_*.]', '', filename)\n",
    "    soup = BeautifulSoup(open(f'lyrics_{filename}.html'), \"html.parser\")\n",
    "    text = cleaning(soup)\n",
    "    all_lyrics += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving combined lyrics locally\n",
    "f = open('all_lyrics.csv','w')\n",
    "f.write(all_lyrics) #Give your csv text here.\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
